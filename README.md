# Instagram Data Engineering Pipeline ğŸš€

**Status:** âœ… Completed

## ğŸ“– Table of Contents  
- [About the project](#about-the-project)  
- [Technologies](#technologies)  
- [Repository Structure](#repository-structure)  
- [Pipeline Overview](#pipeline-overview)  
- [Setup & Run](#setup--run)  
- [Future Improvements](#future-improvements)  
- [Author / Contact](#author--contact)  

## About the project  
This project builds an end-to-end data engineering pipeline using Databricks and PySpark, based on Instagram post data.  
It processes raw data (Bronze), applies transformations and cleaning (Silver), and produces analytics-ready tables (Gold) â€” enabling social media analytics and insights generation.

## Technologies  
- Databricks  
- PySpark / Spark SQL  
- Delta Lake  
- Python 3.x  

## ğŸ“ Repository Structure
- **Instagram-Data-Engineering-Pipeline**
  - `notebooks_clean/` â€” Cleaned notebooks / scripts
    - `0.1 Bronze.py`
    - `0.2 Silver.py`
    - `0.3 Gold.py`
  - `data/` â€” Instagram_Analytics.csv
  - `README.md` â€” This file
  - `LICENSE`



## Pipeline Overview  
- **Bronze**: raw data ingestion, normalization, and persistence as Delta table  
- **Silver**: data cleaning, type casting, date/time parsing, standardization  
- **Gold**: final analytics tables â€” ready for business insights  

Raw Data â†’ Bronze (Delta Raw) â†’ Silver (Cleaned) â†’ Gold (Analytics)

## Setup & Run  
1. Clone the repository  
2. Import notebooks/scripts into Databricks  
3. Configure your Spark/Databricks environment  
4. Run pipeline in order: `Bronze â†’ Silver â†’ Gold`  
5. Check resulting tables in catalog / workspace  

## Future Improvements  
- Add automated tests / data quality checks  
- Parameterize pipeline (config file)  
- Schedule with orchestration (Airflow/Jobs)  
- Extend with more social media metrics / dashboards  

## Author  
Sam Mendes â€” https://www.linkedin.com/in/samuel-mendes1/  
